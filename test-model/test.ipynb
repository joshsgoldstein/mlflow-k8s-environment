{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Configs"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os \n","import pandas as pd \n","# private key to access the storage account \n","# os.environ['GOOGLE_APPLICATION_CREDENTIALS']='./keyfile.json' # Specify the gcs authentification file path \n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/josh/opt/anaconda3/envs/data-science/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n","  from pandas import MultiIndex, Int64Index\n"]},{"name":"stdout","output_type":"stream","text":["MLflow Version: 1.24.0\n","MLflow Tracking URI: http://localhost:5000\n","XGBoost version: 1.5.2\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.model_selection import train_test_split\n","import xgboost as xgb\n","import mlflow\n","import mlflow.xgboost\n","\n","mlflow.set_tracking_uri('http://localhost:5000') # Change to Mlflow URI  (loadbalancer ip)\n","print(\"MLflow Version:\", mlflow.__version__)\n","print(\"MLflow Tracking URI:\", mlflow.get_tracking_uri())\n","print(\"XGBoost version:\",xgb.__version__)\n","client = mlflow.tracking.MlflowClient()\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Train and register a model"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def build_data(data_path):\n","    data = pd.read_csv(data_path)\n","    train, test = train_test_split(data, test_size=0.3, random_state=1)\n","\n","    # The predicted column is \"quality\" which is a scalar from [3, 9]\n","    X_train, X_test = train.drop([\"quality\"], axis=1), test.drop([\"quality\"], axis=1)\n","    y_train, y_test = train[\"quality\"], test[\"quality\"]\n","\n","    return X_train, X_test, y_train, y_test \n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def train(data_path, max_depth, min_child_weight, estimators, model_name):\n","    X_train, X_test, y_train, y_test = build_data(data_path)\n","    with mlflow.start_run() as run:\n","        # Start mlflow session\n","        run_id = run.info.run_uuid\n","        experiment_id = run.info.experiment_id\n","        print(\"MLflow:\")\n","        print(\"  run_id:\", run_id)\n","        print(\"  experiment_id:\", experiment_id)\n","        print(\"  experiment_name:\", client.get_experiment(experiment_id).name)\n","\n","        # MLflow params\n","        print(\"Parameters:\")\n","        print(\"  max_depth:\", max_depth)\n","        print(\"  min_child_weight:\", min_child_weight)\n","        print(\"  estimators:\", estimators)\n","        \n","        mlflow.log_param(\"max_depth\", max_depth)\n","        mlflow.log_param(\"min_child_weight\", min_child_weight)\n","        mlflow.log_param(\"estimators\", estimators)\n","\n","        # Create and fit model\n","        model = xgb.XGBRegressor(\n","                 max_depth=max_depth,\n","                 min_child_weight=min_child_weight,\n","                 random_state=42) \n","        model.fit(X_train, y_train)\n","        \n","        # MLflow metrics\n","        predictions = model.predict(X_test)\n","        print(\"predictions:\",predictions)\n","        rmse = np.sqrt(mean_squared_error(y_test, predictions))\n","        mae = mean_absolute_error(y_test, predictions)\n","        r2 = r2_score(y_test, predictions)\n","        \n","        print(\"Metrics:\")\n","        print(\"  rmse:\", rmse)\n","        print(\"  mae:\", mae)\n","        print(\"  r2:\", r2)\n","        \n","        mlflow.log_metric(\"rmse\", rmse)\n","        mlflow.log_metric(\"r2\", r2)\n","        mlflow.log_metric(\"mae\", mae)\n","\n","        # Log model\n","        mlflow.xgboost.log_model(model, \"xgboost-model\", registered_model_name = model_name)\n"]},{"cell_type":"code","execution_count":13,"metadata":{"scrolled":false},"outputs":[{"name":"stdout","output_type":"stream","text":["MLflow:\n","  run_id: 79a1effc42a14c84832b940f54f3c94c\n","  experiment_id: 0\n","  experiment_name: Default\n","Parameters:\n","  max_depth: 10\n","  min_child_weight: 1\n","  estimators: 100\n"]},{"name":"stderr","output_type":"stream","text":["/Users/josh/opt/anaconda3/envs/data-science/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n","  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"]},{"name":"stdout","output_type":"stream","text":["predictions: [4.7992506 5.165539  6.6657195 ... 6.088301  5.998179  6.1720996]\n","Metrics:\n","  rmse: 0.6374228524913463\n","  mae: 0.42470703043905245\n","  r2: 0.45379700585493965\n"]},{"ename":"S3UploadFailedError","evalue":"Failed to upload /var/folders/xv/n51qjph14_52lj9y4706w6sc0000gn/T/tmppdrj3p61/model/requirements.txt to mlflow/0/79a1effc42a14c84832b940f54f3c94c/artifacts/xgboost-model/requirements.txt: An error occurred (AccessDenied) when calling the PutObject operation: Access Denied","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)","File \u001b[0;32m~/opt/anaconda3/envs/data-science/lib/python3.9/site-packages/boto3/s3/transfer.py:288\u001b[0m, in \u001b[0;36mS3Transfer.upload_file\u001b[0;34m(self, filename, bucket, key, callback, extra_args)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 288\u001b[0m     future\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    289\u001b[0m \u001b[39m# If a client error was raised, add the backwards compatibility layer\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m# that raises a S3UploadFailedError. These specific errors were only\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[39m# ever thrown for upload_parts but now can be thrown for any related\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[39m# client error.\u001b[39;00m\n","File \u001b[0;32m~/opt/anaconda3/envs/data-science/lib/python3.9/site-packages/s3transfer/futures.py:103\u001b[0m, in \u001b[0;36mTransferFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     \u001b[39m# Usually the result() method blocks until the transfer is done,\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[39m# however if a KeyboardInterrupt is raised we want want to exit\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     \u001b[39m# out of this and propagate the exception.\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_coordinator\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    104\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n","File \u001b[0;32m~/opt/anaconda3/envs/data-science/lib/python3.9/site-packages/s3transfer/futures.py:266\u001b[0m, in \u001b[0;36mTransferCoordinator.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m--> 266\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    267\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n","File \u001b[0;32m~/opt/anaconda3/envs/data-science/lib/python3.9/site-packages/s3transfer/tasks.py:139\u001b[0m, in \u001b[0;36mTask.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transfer_coordinator\u001b[39m.\u001b[39mdone():\n\u001b[0;32m--> 139\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_main(kwargs)\n\u001b[1;32m    140\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n","File \u001b[0;32m~/opt/anaconda3/envs/data-science/lib/python3.9/site-packages/s3transfer/tasks.py:162\u001b[0m, in \u001b[0;36mTask._execute_main\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExecuting task \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m with kwargs \u001b[39m\u001b[39m{\u001b[39;00mkwargs_to_display\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 162\u001b[0m return_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_main(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    163\u001b[0m \u001b[39m# If the task is the final task, then set the TransferFuture's\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39m# value to the return value from main().\u001b[39;00m\n","File \u001b[0;32m~/opt/anaconda3/envs/data-science/lib/python3.9/site-packages/s3transfer/upload.py:758\u001b[0m, in \u001b[0;36mPutObjectTask._main\u001b[0;34m(self, client, fileobj, bucket, key, extra_args)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[39mwith\u001b[39;00m fileobj \u001b[39mas\u001b[39;00m body:\n\u001b[0;32m--> 758\u001b[0m     client\u001b[39m.\u001b[39;49mput_object(Bucket\u001b[39m=\u001b[39;49mbucket, Key\u001b[39m=\u001b[39;49mkey, Body\u001b[39m=\u001b[39;49mbody, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_args)\n","File \u001b[0;32m~/opt/anaconda3/envs/data-science/lib/python3.9/site-packages/botocore/client.py:508\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[39m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 508\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_api_call(operation_name, kwargs)\n","File \u001b[0;32m~/opt/anaconda3/envs/data-science/lib/python3.9/site-packages/botocore/client.py:915\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    914\u001b[0m     error_class \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 915\u001b[0m     \u001b[39mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    916\u001b[0m \u001b[39melse\u001b[39;00m:\n","\u001b[0;31mClientError\u001b[0m: An error occurred (AccessDenied) when calling the PutObject operation: Access Denied","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mS3UploadFailedError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32m/Users/josh/Documents/whatamithinking/pipeline-mlflow/k8s-way/test-model/test.ipynb Cell 7\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josh/Documents/whatamithinking/pipeline-mlflow/k8s-way/test-model/test.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m min_child_weight \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josh/Documents/whatamithinking/pipeline-mlflow/k8s-way/test-model/test.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m estimators \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/josh/Documents/whatamithinking/pipeline-mlflow/k8s-way/test-model/test.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m train(data_path, max_depth , min_child_weight, estimators, model_name)\n","\u001b[1;32m/Users/josh/Documents/whatamithinking/pipeline-mlflow/k8s-way/test-model/test.ipynb Cell 7\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_path, max_depth, min_child_weight, estimators, model_name)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josh/Documents/whatamithinking/pipeline-mlflow/k8s-way/test-model/test.ipynb#X10sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m mlflow\u001b[39m.\u001b[39mlog_metric(\u001b[39m\"\u001b[39m\u001b[39mmae\u001b[39m\u001b[39m\"\u001b[39m, mae)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josh/Documents/whatamithinking/pipeline-mlflow/k8s-way/test-model/test.ipynb#X10sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# Log model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/josh/Documents/whatamithinking/pipeline-mlflow/k8s-way/test-model/test.ipynb#X10sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m mlflow\u001b[39m.\u001b[39;49mxgboost\u001b[39m.\u001b[39;49mlog_model(model, \u001b[39m\"\u001b[39;49m\u001b[39mxgboost-model\u001b[39;49m\u001b[39m\"\u001b[39;49m, registered_model_name \u001b[39m=\u001b[39;49m model_name)\n","File \u001b[0;32m~/opt/anaconda3/envs/data-science/lib/python3.9/site-packages/mlflow/xgboost/__init__.py:247\u001b[0m, in \u001b[0;36mlog_model\u001b[0;34m(xgb_model, artifact_path, conda_env, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39m@format_docstring\u001b[39m(LOG_MODEL_PARAM_DOCS\u001b[39m.\u001b[39mformat(package_name\u001b[39m=\u001b[39mFLAVOR_NAME))\n\u001b[1;32m    197\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_model\u001b[39m(\n\u001b[1;32m    198\u001b[0m     xgb_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    208\u001b[0m ):\n\u001b[1;32m    209\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[39m    Log an XGBoost model as an MLflow artifact for the current run.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[39m             metadata of the logged model.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m     \u001b[39mreturn\u001b[39;00m Model\u001b[39m.\u001b[39;49mlog(\n\u001b[1;32m    248\u001b[0m         artifact_path\u001b[39m=\u001b[39;49martifact_path,\n\u001b[1;32m    249\u001b[0m         flavor\u001b[39m=\u001b[39;49mmlflow\u001b[39m.\u001b[39;49mxgboost,\n\u001b[1;32m    250\u001b[0m         registered_model_name\u001b[39m=\u001b[39;49mregistered_model_name,\n\u001b[1;32m    251\u001b[0m         xgb_model\u001b[39m=\u001b[39;49mxgb_model,\n\u001b[1;32m    252\u001b[0m         conda_env\u001b[39m=\u001b[39;49mconda_env,\n\u001b[1;32m    253\u001b[0m         signature\u001b[39m=\u001b[39;49msignature,\n\u001b[1;32m    254\u001b[0m         input_example\u001b[39m=\u001b[39;49minput_example,\n\u001b[1;32m    255\u001b[0m         await_registration_for\u001b[39m=\u001b[39;49mawait_registration_for,\n\u001b[1;32m    256\u001b[0m         pip_requirements\u001b[39m=\u001b[39;49mpip_requirements,\n\u001b[1;32m    257\u001b[0m         extra_pip_requirements\u001b[39m=\u001b[39;49mextra_pip_requirements,\n\u001b[1;32m    258\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    259\u001b[0m     )\n","File \u001b[0;32m~/opt/anaconda3/envs/data-science/lib/python3.9/site-packages/mlflow/models/model.py:283\u001b[0m, in \u001b[0;36mModel.log\u001b[0;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, **kwargs)\u001b[0m\n\u001b[1;32m    281\u001b[0m mlflow_model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(artifact_path\u001b[39m=\u001b[39martifact_path, run_id\u001b[39m=\u001b[39mrun_id)\n\u001b[1;32m    282\u001b[0m flavor\u001b[39m.\u001b[39msave_model(path\u001b[39m=\u001b[39mlocal_path, mlflow_model\u001b[39m=\u001b[39mmlflow_model, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 283\u001b[0m mlflow\u001b[39m.\u001b[39;49mtracking\u001b[39m.\u001b[39;49mfluent\u001b[39m.\u001b[39;49mlog_artifacts(local_path, artifact_path)\n\u001b[1;32m    284\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    285\u001b[0m     mlflow\u001b[39m.\u001b[39mtracking\u001b[39m.\u001b[39mfluent\u001b[39m.\u001b[39m_record_logged_model(mlflow_model)\n","File \u001b[0;32m~/opt/anaconda3/envs/data-science/lib/python3.9/site-packages/mlflow/tracking/fluent.py:654\u001b[0m, in \u001b[0;36mlog_artifacts\u001b[0;34m(local_dir, artifact_path)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \u001b[39mLog all the contents of a local directory as artifacts of the run. If no run is active,\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[39mthis method will create a new active run.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[39m        mlflow.log_artifacts(\"data\", artifact_path=\"states\")\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    653\u001b[0m run_id \u001b[39m=\u001b[39m _get_or_start_run()\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mrun_id\n\u001b[0;32m--> 654\u001b[0m MlflowClient()\u001b[39m.\u001b[39;49mlog_artifacts(run_id, local_dir, artifact_path)\n","File \u001b[0;32m~/opt/anaconda3/envs/data-science/lib/python3.9/site-packages/mlflow/tracking/client.py:1001\u001b[0m, in \u001b[0;36mMlflowClient.log_artifacts\u001b[0;34m(self, run_id, local_dir, artifact_path)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_artifacts\u001b[39m(\n\u001b[1;32m    958\u001b[0m     \u001b[39mself\u001b[39m, run_id: \u001b[39mstr\u001b[39m, local_dir: \u001b[39mstr\u001b[39m, artifact_path: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    959\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    960\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    961\u001b[0m \u001b[39m    Write a directory of files to the remote ``artifact_uri``.\u001b[39;00m\n\u001b[1;32m    962\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    999\u001b[0m \u001b[39m        is_dir: True\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1001\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tracking_client\u001b[39m.\u001b[39;49mlog_artifacts(run_id, local_dir, artifact_path)\n","File \u001b[0;32m~/opt/anaconda3/envs/data-science/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py:364\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_artifacts\u001b[0;34m(self, run_id, local_dir, artifact_path)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_artifacts\u001b[39m(\u001b[39mself\u001b[39m, run_id, local_dir, artifact_path\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    358\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[39m    Write a directory of files to the remote ``artifact_uri``.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[39m    :param local_dir: Path to the directory of files to write.\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[39m    :param artifact_path: If provided, the directory in ``artifact_uri`` to write to.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_artifact_repo(run_id)\u001b[39m.\u001b[39;49mlog_artifacts(local_dir, artifact_path)\n","File \u001b[0;32m~/opt/anaconda3/envs/data-science/lib/python3.9/site-packages/mlflow/store/artifact/s3_artifact_repo.py:141\u001b[0m, in \u001b[0;36mS3ArtifactRepository.log_artifacts\u001b[0;34m(self, local_dir, artifact_path)\u001b[0m\n\u001b[1;32m    139\u001b[0m     upload_path \u001b[39m=\u001b[39m posixpath\u001b[39m.\u001b[39mjoin(dest_path, rel_path)\n\u001b[1;32m    140\u001b[0m \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m filenames:\n\u001b[0;32m--> 141\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_upload_file(\n\u001b[1;32m    142\u001b[0m         s3_client\u001b[39m=\u001b[39;49ms3_client,\n\u001b[1;32m    143\u001b[0m         local_file\u001b[39m=\u001b[39;49mos\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(root, f),\n\u001b[1;32m    144\u001b[0m         bucket\u001b[39m=\u001b[39;49mbucket,\n\u001b[1;32m    145\u001b[0m         key\u001b[39m=\u001b[39;49mposixpath\u001b[39m.\u001b[39;49mjoin(upload_path, f),\n\u001b[1;32m    146\u001b[0m     )\n","File \u001b[0;32m~/opt/anaconda3/envs/data-science/lib/python3.9/site-packages/mlflow/store/artifact/s3_artifact_repo.py:117\u001b[0m, in \u001b[0;36mS3ArtifactRepository._upload_file\u001b[0;34m(self, s3_client, local_file, bucket, key)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m environ_extra_args \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m     extra_args\u001b[39m.\u001b[39mupdate(environ_extra_args)\n\u001b[0;32m--> 117\u001b[0m s3_client\u001b[39m.\u001b[39;49mupload_file(Filename\u001b[39m=\u001b[39;49mlocal_file, Bucket\u001b[39m=\u001b[39;49mbucket, Key\u001b[39m=\u001b[39;49mkey, ExtraArgs\u001b[39m=\u001b[39;49mextra_args)\n","File \u001b[0;32m~/opt/anaconda3/envs/data-science/lib/python3.9/site-packages/boto3/s3/inject.py:143\u001b[0m, in \u001b[0;36mupload_file\u001b[0;34m(self, Filename, Bucket, Key, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39m\"\"\"Upload a file to an S3 object.\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \n\u001b[1;32m    110\u001b[0m \u001b[39mUsage::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39m    transfer.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[39mwith\u001b[39;00m S3Transfer(\u001b[39mself\u001b[39m, Config) \u001b[39mas\u001b[39;00m transfer:\n\u001b[0;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m transfer\u001b[39m.\u001b[39;49mupload_file(\n\u001b[1;32m    144\u001b[0m         filename\u001b[39m=\u001b[39;49mFilename,\n\u001b[1;32m    145\u001b[0m         bucket\u001b[39m=\u001b[39;49mBucket,\n\u001b[1;32m    146\u001b[0m         key\u001b[39m=\u001b[39;49mKey,\n\u001b[1;32m    147\u001b[0m         extra_args\u001b[39m=\u001b[39;49mExtraArgs,\n\u001b[1;32m    148\u001b[0m         callback\u001b[39m=\u001b[39;49mCallback,\n\u001b[1;32m    149\u001b[0m     )\n","File \u001b[0;32m~/opt/anaconda3/envs/data-science/lib/python3.9/site-packages/boto3/s3/transfer.py:294\u001b[0m, in \u001b[0;36mS3Transfer.upload_file\u001b[0;34m(self, filename, bucket, key, callback, extra_args)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[39m# If a client error was raised, add the backwards compatibility layer\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m# that raises a S3UploadFailedError. These specific errors were only\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[39m# ever thrown for upload_parts but now can be thrown for any related\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[39m# client error.\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[39mexcept\u001b[39;00m ClientError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 294\u001b[0m     \u001b[39mraise\u001b[39;00m S3UploadFailedError(\n\u001b[1;32m    295\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFailed to upload \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    296\u001b[0m             filename, \u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([bucket, key]), e\n\u001b[1;32m    297\u001b[0m         )\n\u001b[1;32m    298\u001b[0m     )\n","\u001b[0;31mS3UploadFailedError\u001b[0m: Failed to upload /var/folders/xv/n51qjph14_52lj9y4706w6sc0000gn/T/tmppdrj3p61/model/requirements.txt to mlflow/0/79a1effc42a14c84832b940f54f3c94c/artifacts/xgboost-model/requirements.txt: An error occurred (AccessDenied) when calling the PutObject operation: Access Denied"]}],"source":["data_path = './wine-quality-white.csv'\n","experiment_name = 'test_xgboost'\n","model_name = 'xgb_0'\n","max_depth = 10\n","min_child_weight = 1\n","estimators = 100\n","train(data_path, max_depth , min_child_weight, estimators, model_name)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Load the model from mlflow and make predictions"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["array([6.0004535, 5.994977 , 5.629604 , 5.9799094, 5.9799094],\n","      dtype=float32)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Predict on a Pandas DataFrame\n","\n","import pandas as pd\n","\n","test_samples =pd.read_csv(data_path).head(5).drop(columns=['quality'])\n","loaded_model = mlflow.pyfunc.load_model(\"runs:/a0928931dff54a829b881be2a3e41d00/xgboost-model\")\n","loaded_model.predict(test_samples)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.7 ('data-science')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"a64daf48265175ab4f9e3b4f218504d1fb45289ba63ff66be172e6ba46f72957"}}},"nbformat":4,"nbformat_minor":4}
